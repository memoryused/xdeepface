{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8133a99d",
   "metadata": {},
   "source": [
    "# Perform Experiments with DeepFace on My dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5aab0cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# built-in dependencies\n",
    "import os\n",
    "\n",
    "# 3rd party dependencies\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
    "from sklearn.datasets import fetch_lfw_pairs\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from deepface import DeepFace\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64c9ed9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This experiment is done with pip package of deepface with 0.0.91 version\n"
     ]
    }
   ],
   "source": [
    "print(f\"This experiment is done with pip package of deepface with {DeepFace.__version__} version\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feaec973",
   "metadata": {},
   "source": [
    "### Configuration Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "453104b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all configuration alternatives for 4 dimensions of arguments\n",
    "alignment = [False, True]\n",
    "models = [\"Facenet512\", \"ArcFace\"]\n",
    "detectors = [\"opencv\"]\n",
    "metrics = [\"euclidean\", \"cosine\"]\n",
    "expand_percentage = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9aeb57a",
   "metadata": {},
   "source": [
    "### Create Required Folders if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "671d8a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_paths = [\"lfwe\", \"dataset\", \"outputs\", \"outputs/test\", \"results\"]\n",
    "for target_path in target_paths:\n",
    "    if os.path.exists(target_path) != True:\n",
    "        os.mkdir(target_path)\n",
    "        print(f\"{target_path} is just created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc31f03a",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "721a7d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_touch = \"outputs/test_lfwe.txt\"\n",
    "instances = 1000 #pairs.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c75bd9",
   "metadata": {},
   "source": [
    "### Choice 1 Mimic to fetch_lfw_pairs (Not use because data are imbalance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85848bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"../data_db\"\n",
    "target_path = \"dataset/test_lfw.npy\"\n",
    "labels_path = \"dataset/test_labels.npy\"\n",
    "\n",
    "def create_random_pairs(data_path, num_pairs=1000):\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    class_folders = sorted(os.listdir(data_path))\n",
    "    \n",
    "    for idx, class_folder in enumerate(class_folders):\n",
    "        class_path = os.path.join(data_path, class_folder)\n",
    "        image_files = sorted(os.listdir(class_path))\n",
    "        \n",
    "        for img_file in image_files:\n",
    "            img_path = os.path.join(class_path, img_file)\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None or img.size == 0:\n",
    "                print(f\"Warning: Failed to load image: {img_path}\")\n",
    "            else:\n",
    "                images.append(img)\n",
    "                labels.append(idx)\n",
    "    \n",
    "    # Create all possible pairs\n",
    "    pairs = []\n",
    "    pair_labels = []\n",
    "    \n",
    "    for i in range(len(images)):\n",
    "        for j in range(i+1, len(images)):\n",
    "            pairs.append([images[i], images[j]])\n",
    "            pair_labels.append(1 if labels[i] == labels[j] else 0)\n",
    "    \n",
    "    # Randomly select 1000 pairs\n",
    "    if len(pairs) >= num_pairs:\n",
    "        selected_indices = random.sample(range(len(pairs)), num_pairs)\n",
    "        random_pairs = [pairs[i] for i in selected_indices]\n",
    "        random_labels = [pair_labels[i] for i in selected_indices]\n",
    "    else:\n",
    "        print(f\"Warning: Not enough pairs generated ({len(pairs)}). Check your dataset.\")\n",
    "        random_pairs = pairs\n",
    "        random_labels = pair_labels\n",
    "    \n",
    "    return np.array(random_pairs), np.array(random_labels)\n",
    "\n",
    "if not os.path.exists(target_path) or not os.path.exists(labels_path):\n",
    "    pairs, labels = create_random_pairs(dataset_path, num_pairs=1000)\n",
    "    np.save(target_path, pairs)\n",
    "    np.save(labels_path, labels)\n",
    "else:\n",
    "    pairs = np.load(target_path)\n",
    "    labels = np.load(labels_path)\n",
    "\n",
    "print(f\"Total pairs: {len(pairs)}\")\n",
    "print(f\"Positive pairs: {np.sum(labels == 1)}\")\n",
    "print(f\"Negative pairs: {np.sum(labels == 0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fac54865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate test if i use fetch_lfw_pairs (Not use)\n",
    "target_path = \"dataset/test_lfw.npy\"\n",
    "labels_path = \"dataset/test_labels.npy\"\n",
    "\n",
    "if os.path.exists(target_path) != True:\n",
    "    fetch_lfw_pairs = fetch_lfw_pairs(subset = 'test', data_home='../data_db'\n",
    "                                  , color = True\n",
    "                                  , resize = 2\n",
    "                                  , funneled = False\n",
    "                                  , slice_=None\n",
    "                                 )\n",
    "    pairs = fetch_lfw_pairs.pairs\n",
    "    labels = fetch_lfw_pairs.target\n",
    "    target_names = fetch_lfw_pairs.target_names\n",
    "    np.save(target_path, pairs)\n",
    "    np.save(labels_path, labels)\n",
    "else:\n",
    "    if os.path.exists(pairs_touch) != True:\n",
    "        # loading pairs takes some time. but if we extract these pairs as image, no need to load it anymore\n",
    "        pairs = np.load(target_path)\n",
    "    labels = np.load(labels_path)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72fe346",
   "metadata": {},
   "source": [
    "### Choice 2 Balance the number of positive and negative pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "010184d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pairs: 2162\n",
      "Positive pairs: 1081\n",
      "Negative pairs: 1081\n"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "dataset_path = \"../data_db\"\n",
    "target_path = \"dataset/test_lfw.npy\"\n",
    "labels_path = \"dataset/test_labels.npy\"\n",
    "\n",
    "# Desired image size and number of channels\n",
    "image_size = (224, 224)  # Adjust this size based on your needs\n",
    "num_channels = 3  # 3 for RGB, 1 for grayscale\n",
    "\n",
    "# Function to load images from the dataset folder and resize them\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder, filename))\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, image_size)  # Resize image\n",
    "            if num_channels == 3 and len(img.shape) == 2:\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)  # Convert grayscale to RGB\n",
    "            elif num_channels == 1 and len(img.shape) == 3:\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)  # Convert RGB to grayscale\n",
    "            images.append(img)\n",
    "    return images\n",
    "\n",
    "# Initialize empty lists for pairs and labels\n",
    "positive_pairs = []\n",
    "negative_pairs = []\n",
    "\n",
    "# Load all images and store them in a dictionary by person name\n",
    "all_images = {}\n",
    "for person_name in os.listdir(dataset_path):\n",
    "    person_folder = os.path.join(dataset_path, person_name)\n",
    "    if os.path.isdir(person_folder):\n",
    "        images = load_images_from_folder(person_folder)\n",
    "        if len(images) > 1:  # Only consider folders with more than 1 image\n",
    "            all_images[person_name] = images\n",
    "\n",
    "# Create positive pairs (same person)\n",
    "for person_name, images in all_images.items():\n",
    "    num_images = len(images)\n",
    "    for i in range(num_images):\n",
    "        for j in range(i + 1, num_images):\n",
    "            positive_pairs.append([images[i], images[j]])\n",
    "\n",
    "# Create negative pairs (different persons)\n",
    "person_names = list(all_images.keys())\n",
    "for i in range(len(person_names)):\n",
    "    for j in range(i + 1, len(person_names)):\n",
    "        if len(positive_pairs) > len(negative_pairs):\n",
    "            person_name_1 = person_names[i]\n",
    "            person_name_2 = person_names[j]\n",
    "            img1 = random.choice(all_images[person_name_1])  # Randomly select 1 image from person i\n",
    "            img2 = random.choice(all_images[person_name_2])  # Randomly select 1 image from person j\n",
    "            negative_pairs.append([img1, img2])\n",
    "\n",
    "# Balance the number of positive and negative pairs\n",
    "num_pairs_to_use = min(len(positive_pairs), len(negative_pairs))\n",
    "pairs = positive_pairs[:num_pairs_to_use] + negative_pairs[:num_pairs_to_use]\n",
    "labels = [1] * num_pairs_to_use + [0] * num_pairs_to_use\n",
    "\n",
    "# Shuffle the pairs and labels\n",
    "combined = list(zip(pairs, labels))\n",
    "random.shuffle(combined)\n",
    "pairs, labels = zip(*combined)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "pairs = np.array(pairs)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Save the pairs and labels arrays\n",
    "np.save(target_path, pairs)\n",
    "np.save(labels_path, labels)\n",
    "\n",
    "print(f\"Total pairs: {len(pairs)}\")\n",
    "print(f\"Positive pairs: {np.sum(labels == 1)}\")\n",
    "print(f\"Negative pairs: {np.sum(labels == 0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005f582e",
   "metadata": {},
   "source": [
    "### Save image pairs into file system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5bc23313",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 38560.87it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(0, instances)):\n",
    "    img1_target = f\"lfwe/test/{i}_1.jpg\"\n",
    "    img2_target = f\"lfwe/test/{i}_2.jpg\"\n",
    "    #print(f\"Pair {i}: img1 size = {pairs[i][0].size}, img2 size = {pairs[i][1].size}\")\n",
    "\n",
    "    if os.path.exists(img1_target) != True:\n",
    "        img1 = pairs[i][0]\n",
    "        # plt.imsave(img1_target, img1/255) #works for my mac\n",
    "        img1 = cv2.cvtColor(pairs[i][0], cv2.COLOR_BGR2RGB)\n",
    "        plt.imsave(img1_target, img1) #works for my debian\n",
    "    \n",
    "    if os.path.exists(img2_target) != True:\n",
    "        img2 = pairs[i][1]\n",
    "        # plt.imsave(img2_target, img2/255) #works for my mac\n",
    "        img2 = cv2.cvtColor(pairs[i][1], cv2.COLOR_BGR2RGB)\n",
    "        plt.imsave(img2_target, img2) #works for my debian\n",
    "    \n",
    "if os.path.exists(pairs_touch) != True:\n",
    "    open(pairs_touch,'a').close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8fa8fa",
   "metadata": {},
   "source": [
    "### Perform Experiments\n",
    "\n",
    "This block will save the experiments results in outputs folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7fba936",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Facenet512_opencv_euclidean_unaligned: 100%|██████████| 1000/1000 [07:43<00:00,  2.16it/s]\n",
      "Facenet512_opencv_euclidean_aligned: 100%|██████████| 1000/1000 [08:27<00:00,  1.97it/s]\n",
      "Facenet512_opencv_cosine_unaligned: 100%|██████████| 1000/1000 [08:14<00:00,  2.02it/s]\n",
      "Facenet512_opencv_cosine_aligned: 100%|██████████| 1000/1000 [08:15<00:00,  2.02it/s]\n",
      "ArcFace_opencv_euclidean_unaligned: 100%|██████████| 1000/1000 [07:39<00:00,  2.18it/s]\n",
      "ArcFace_opencv_euclidean_aligned: 100%|██████████| 1000/1000 [07:27<00:00,  2.23it/s]\n",
      "ArcFace_opencv_cosine_unaligned: 100%|██████████| 1000/1000 [07:31<00:00,  2.21it/s]\n",
      "ArcFace_opencv_cosine_aligned: 100%|██████████| 1000/1000 [07:38<00:00,  2.18it/s]\n"
     ]
    }
   ],
   "source": [
    "# Define how many instances you want to process\n",
    "\n",
    "for model_name in models:\n",
    "    for detector_backend in detectors:\n",
    "        for distance_metric in metrics:\n",
    "            for align in alignment:\n",
    "                \n",
    "                if detector_backend == \"skip\" and align is True:\n",
    "                    # Alignment is not possible for a skipped detector configuration\n",
    "                    continue\n",
    "                \n",
    "                alignment_text = \"aligned\" if align is True else \"unaligned\"\n",
    "                task = f\"{model_name}_{detector_backend}_{distance_metric}_{alignment_text}\"\n",
    "                output_file = f\"outputs/test/{task}.csv\"\n",
    "                if os.path.exists(output_file) is True:\n",
    "                     #print(f\"{output_file} is available already\")\n",
    "                     continue\n",
    "                \n",
    "                distances = []\n",
    "                for i in tqdm(range(0, instances), desc = task):\n",
    "                    img1_target = f\"lfwe/test/{i}_1.jpg\"\n",
    "                    img2_target = f\"lfwe/test/{i}_2.jpg\"\n",
    "                    result = DeepFace.verify(\n",
    "                        img1_path=img1_target,\n",
    "                        img2_path=img2_target,\n",
    "                        model_name=model_name,\n",
    "                        detector_backend=detector_backend,\n",
    "                        distance_metric=distance_metric,\n",
    "                        align=align,\n",
    "                        enforce_detection=False,\n",
    "                        expand_percentage=expand_percentage,\n",
    "                    )\n",
    "                    distance = result[\"distance\"]\n",
    "                    distances.append(distance)\n",
    "                # -----------------------------------\n",
    "                df = pd.DataFrame({\"actuals\": labels[:instances]})\n",
    "                df[\"distances\"] = distances\n",
    "                df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b8dafa",
   "metadata": {},
   "source": [
    "### Calculate Results\n",
    "\n",
    "Experiments were responsible for calculating distances. We will calculate the best accuracy scores in this block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67376e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[0 for _ in range(len(models))] for _ in range(len(detectors))]\n",
    "base_df = pd.DataFrame(data, columns=models, index=detectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2cc536b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Facenet512\n",
      "0.811802453685039\n",
      "0.7869587628865978\n",
      "[]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.905     0.506     0.649       506\n",
      "           1      0.651     0.945     0.771       494\n",
      "\n",
      "    accuracy                          0.723      1000\n",
      "   macro avg      0.778     0.726     0.710      1000\n",
      "weighted avg      0.779     0.723     0.709      1000\n",
      "\n",
      "threshold for Facenet512/opencv is 22.90168547542397\n",
      "outputs/test/Facenet512_opencv_euclidean_unaligned.csv 83.1\n",
      "ArcFace\n",
      "0.7689264991728961\n",
      "0.7538173076923077\n",
      "[]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.753     0.447     0.561       506\n",
      "           1      0.600     0.850     0.704       494\n",
      "\n",
      "    accuracy                          0.646      1000\n",
      "   macro avg      0.677     0.648     0.632      1000\n",
      "weighted avg      0.678     0.646     0.631      1000\n",
      "\n",
      "threshold for ArcFace/opencv is 4.886483578563145\n",
      "outputs/test/ArcFace_opencv_euclidean_unaligned.csv 80.6\n",
      "results/pivot_euclidean_with_alignment_False.csv saved\n",
      "Facenet512\n",
      "0.8196556428256\n",
      "0.8041649214659685\n",
      "[]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.849     0.543     0.663       506\n",
      "           1      0.658     0.901     0.761       494\n",
      "\n",
      "    accuracy                          0.720      1000\n",
      "   macro avg      0.754     0.722     0.712      1000\n",
      "weighted avg      0.755     0.720     0.711      1000\n",
      "\n",
      "threshold for Facenet512/opencv is 0.510667932841821\n",
      "outputs/test/Facenet512_opencv_cosine_unaligned.csv 83.9\n",
      "ArcFace\n",
      "0.7823836924839142\n",
      "0.7645298507462687\n",
      "[]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.829     0.567     0.674       506\n",
      "           1      0.665     0.881     0.758       494\n",
      "\n",
      "    accuracy                          0.722      1000\n",
      "   macro avg      0.747     0.724     0.716      1000\n",
      "weighted avg      0.748     0.722     0.715      1000\n",
      "\n",
      "threshold for ArcFace/opencv is 0.7087412174199201\n",
      "outputs/test/ArcFace_opencv_cosine_unaligned.csv 78.6\n",
      "results/pivot_cosine_with_alignment_False.csv saved\n",
      "Facenet512\n",
      "0.809701702616022\n",
      "0.7858514644351464\n",
      "[]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.901     0.506     0.648       506\n",
      "           1      0.651     0.943     0.770       494\n",
      "\n",
      "    accuracy                          0.722      1000\n",
      "   macro avg      0.776     0.725     0.709      1000\n",
      "weighted avg      0.778     0.722     0.708      1000\n",
      "\n",
      "threshold for Facenet512/opencv is 22.869648311287783\n",
      "outputs/test/Facenet512_opencv_euclidean_aligned.csv 82.9\n",
      "ArcFace\n",
      "0.7667077781214793\n",
      "0.7525940594059406\n",
      "[]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.752     0.449     0.562       506\n",
      "           1      0.600     0.848     0.703       494\n",
      "\n",
      "    accuracy                          0.646      1000\n",
      "   macro avg      0.676     0.648     0.632      1000\n",
      "weighted avg      0.677     0.646     0.632      1000\n",
      "\n",
      "threshold for ArcFace/opencv is 4.927813624910536\n",
      "outputs/test/ArcFace_opencv_euclidean_aligned.csv 80.5\n",
      "results/pivot_euclidean_with_alignment_True.csv saved\n",
      "Facenet512\n",
      "0.8168403258818281\n",
      "0.8014947643979059\n",
      "[]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.848     0.542     0.661       506\n",
      "           1      0.657     0.901     0.760       494\n",
      "\n",
      "    accuracy                          0.719      1000\n",
      "   macro avg      0.753     0.721     0.711      1000\n",
      "weighted avg      0.754     0.719     0.710      1000\n",
      "\n",
      "threshold for Facenet512/opencv is 0.5336192824709401\n",
      "outputs/test/Facenet512_opencv_cosine_aligned.csv 83.5\n",
      "ArcFace\n",
      "0.7815665918324668\n",
      "0.764246192893401\n",
      "[]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.817     0.565     0.668       506\n",
      "           1      0.662     0.870     0.752       494\n",
      "\n",
      "    accuracy                          0.716      1000\n",
      "   macro avg      0.739     0.718     0.710      1000\n",
      "weighted avg      0.740     0.716     0.709      1000\n",
      "\n",
      "threshold for ArcFace/opencv is 0.6495128957609713\n",
      "outputs/test/ArcFace_opencv_cosine_aligned.csv 79.5\n",
      "results/pivot_cosine_with_alignment_True.csv saved\n"
     ]
    }
   ],
   "source": [
    "for is_aligned in alignment:\n",
    "    for distance_metric in metrics:\n",
    "\n",
    "        current_df = base_df.copy()\n",
    "        \n",
    "        target_file = f\"results/pivot_{distance_metric}_with_alignment_{is_aligned}.csv\"\n",
    "        if os.path.exists(target_file):\n",
    "            continue\n",
    "        \n",
    "        for model_name in models:\n",
    "            for detector_backend in detectors:\n",
    "\n",
    "                align = \"aligned\" if is_aligned is True else \"unaligned\"\n",
    "\n",
    "                if detector_backend == \"skip\" and is_aligned is True:\n",
    "                    # Alignment is not possible for a skipped detector configuration\n",
    "                    align = \"unaligned\"\n",
    "\n",
    "                source_file = f\"outputs/test/{model_name}_{detector_backend}_{distance_metric}_{align}.csv\"\n",
    "                df = pd.read_csv(source_file)\n",
    "                  \n",
    "                positive_mean = df[(df[\"actuals\"] == True) | (df[\"actuals\"] == 1)][\"distances\"].mean()\n",
    "                negative_mean = df[(df[\"actuals\"] == False) | (df[\"actuals\"] == 0)][\"distances\"].mean()\n",
    "\n",
    "                distances = sorted(df[\"distances\"].values.tolist())\n",
    "                #print(positive_mean)\n",
    "                #print(negative_mean)\n",
    "                #print(distances)\n",
    "                items = []\n",
    "                precision = []\n",
    "                recall = []\n",
    "                f1_scores = []\n",
    "                for i, distance in enumerate(distances):\n",
    "                    if distance >= positive_mean and distance <= negative_mean:\n",
    "                        sandbox_df = df.copy()\n",
    "                        sandbox_df[\"predictions\"] = False\n",
    "                        idx = sandbox_df[sandbox_df[\"distances\"] < distance].index\n",
    "                        sandbox_df.loc[idx, \"predictions\"] = True\n",
    "\n",
    "                        actuals = sandbox_df.actuals.values.tolist()\n",
    "                        predictions = sandbox_df.predictions.values.tolist()\n",
    "                        accuracy = 100*accuracy_score(actuals, predictions)\n",
    "                        items.append((distance, accuracy))\n",
    "\n",
    "                        precision.append(precision_score(actuals, predictions, average=\"weighted\"))\n",
    "                        recall.append(recall_score(actuals, predictions, average=\"weighted\"))\n",
    "                        #f1_scores.append(f1_score(actuals, predictions, average=\"macro\"))\n",
    "\n",
    "                pivot_df = pd.DataFrame(items, columns = [\"distance\", \"accuracy\"])\n",
    "                pivot_df = pivot_df.sort_values(by = [\"accuracy\"], ascending = False)\n",
    "                print(model_name)\n",
    "                print(np.average(precision))\n",
    "                print(np.average(recall))\n",
    "                print(f1_scores)\n",
    "                # encode the labels\n",
    "                #le = LabelEncoder()\n",
    "                #le.fit_transform(labels)\n",
    "                print(classification_report(actuals, predictions, digits=3))\n",
    "                threshold = pivot_df.iloc[0][\"distance\"]\n",
    "                print(f\"threshold for {model_name}/{detector_backend} is {threshold}\")\n",
    "                accuracy = pivot_df.iloc[0][\"accuracy\"]\n",
    "\n",
    "                print(source_file, round(accuracy, 1))\n",
    "                current_df.at[detector_backend, model_name] = round(accuracy, 1)\n",
    "        \n",
    "        current_df.to_csv(target_file)\n",
    "        print(f\"{target_file} saved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
